{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cadaafd",
   "metadata": {},
   "source": [
    "### Basic React Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7336cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm functioning properly, thank you for asking. What would you like to talk about or ask today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model=init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "response=model.invoke(\"Hello, how are you?\")\n",
    "print(response.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba842d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def getWeather(city:str)->str:\n",
    "    \"\"\"Get the weather of a city\"\"\"\n",
    "    return f\"The weather of {city} is always cold\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e286f515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'getWeather',\n",
       "  'args': {'city': 'San Francisco'},\n",
       "  'id': 'm4nah4e8d',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools=model.bind_tools([getWeather])\n",
    "response=model_with_tools.invoke(\"What is the weather of San Francisco?\")\n",
    "response.tool_calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580a74f5",
   "metadata": {},
   "source": [
    "### Tools Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4afaf81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's not correct. The weather in San Francisco can vary greatly depending on the time of year and other factors. \n",
      "\n",
      "To get the actual weather, I should have used the getWeather function. Let me try that again.\n",
      "\n",
      " <function=getWeather>{\"city\": \"San Francisco\"}</function>\n",
      "\n",
      "The output will be the current weather in San Francisco.\n",
      "\n",
      "Note: Since you didn't provide the actual output of the function, I couldn't give you the correct weather of San Francisco.\n"
     ]
    }
   ],
   "source": [
    "# Step 1:Model generates tool calls\n",
    "messages =[{\"role\":\"user\",\"content\":\"What is the weather of San Francisco?\"}]\n",
    "ai_msg=model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# Step 2: Execute tools and collect results\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    tool_result=getWeather.invoke(tool_call)\n",
    "    messages.append(tool_result)\n",
    "    \n",
    "# Step 3: Pass results back to model for final response\n",
    "\n",
    "final_response=model_with_tools.invoke(messages)\n",
    "print(final_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b31cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's not correct. The weather in San Francisco can vary greatly depending on the time of year and other factors. Here's a more accurate response:\n",
      "\n",
      "The current weather in San Francisco is not provided as the function getWeather does not actually provide the current weather. However, I can tell you that San Francisco has a Mediterranean climate with cool summers and mild winters. The average temperature in San Francisco ranges from around 46°F (8°C) in January (the coldest month) to around 59°F (15°C) in September (the warmest month).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def getWeather(city: str) -> str:\n",
    "    \"\"\"Get the weather of a city\"\"\"\n",
    "    return f\"The weather of {city} is always cold\"\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools([getWeather])\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather of San Francisco?\"}\n",
    "]\n",
    "\n",
    "# Step 1: model decides to call tool\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# Step 2: execute tool CORRECTLY\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    tool_result = getWeather.invoke(tool_call[\"args\"])\n",
    "\n",
    "    messages.append({\n",
    "        \"role\": \"tool\",\n",
    "        \"tool_call_id\": tool_call[\"id\"],\n",
    "        \"content\": tool_result\n",
    "    })\n",
    "\n",
    "# Step 3: model uses tool result\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "print(final_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbdf0ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather of San Francisco is always hot\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def getWeather(city: str) -> str:\n",
    "    \"\"\"Get the weather of a city\"\"\"\n",
    "    return f\"The weather of {city} is always hot\"\n",
    "\n",
    "\n",
    "model_with_tools = model.bind_tools([getWeather])\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather of San Francisco?\"}\n",
    "]\n",
    "\n",
    "# Step 1: model decides which tool to call\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "\n",
    "# Step 2: execute tool and RETURN RESULT DIRECTLY\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    tool_result = getWeather.invoke(tool_call[\"args\"])\n",
    "    print(tool_result)   # ✅ FINAL ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8bd0cc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x1122d7c80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x112215340>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'getWeather', 'description': 'Get the weather of a city', 'parameters': {'properties': {'city': {'type': 'string'}}, 'required': ['city'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
